<img align="right" src="https://visitor-badge.laobi.icu/badge?page_id=Darylwanji.135DaysofLLM" />

<h1 align="center">
  <img src="https://readme-typing-svg.herokuapp.com/?font=Righteous&size=35&center=true&vCenter=true&width=600&height=70&duration=5000&lines=135+Days+of+LLM+Mastery+ğŸ§ ;From+Foundations+to+AI+Safety;Build+â€¢+Align+â€¢+Interpret+â€¢+Deploy" />
</h1>

<h3 align="center">ğŸš€ Complete Beginner to Expert: LLM Systems + AI Alignment + Interpretability</h3>

<p align="center">
  <img src="https://img.shields.io/badge/Duration-135_Days-blue?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Hours-400+-purple?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Projects-15+-green?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Version-2.0_Extended-orange?style=for-the-badge" />
</p>

<p align="center">
  A comprehensive, structured learning roadmap to master <strong>LLM systems, AI alignment, mechanistic interpretability, and AI safety</strong>. 
  From GPU architecture fundamentals to building production-grade systems and understanding what's happening inside neural networks.
</p>

---

## ğŸ“‹ Roadmap Overview

| Phase | Days | Theme | Focus Areas |
|:------|:-----|:------|:------------|
| **1** | 1-20 | ğŸ”§ Foundations | GPU architecture, Transformers, basic inference |
| **2** | 21-39 | âš¡ Inference Optimization | Quantization, attention mechanisms, serving |
| **3** | 40-59 | ğŸŒ Distributed Systems | Multi-GPU training, parallelism, orchestration |
| **4** | 60-90 | ğŸš€ Production & Frontiers | MLOps, deployment, edge AI, capstone |
| **5** | 91-105 | ğŸ¯ AI Alignment | RLHF, DPO, Constitutional AI, reward hacking |
| **6** | 106-120 | ğŸ”¬ Mechanistic Interpretability | SAEs, circuits, feature analysis, steering |
| **7** | 121-135 | ğŸ›¡ï¸ Advanced AI Safety | Capability evals, red teaming, scalable oversight |

---

## ğŸ¯ Why This Roadmap?

> *"Understanding what large models are 'thinking' is no longer optional but a prerequisite for safe deployment."*
> â€” Dario Amodei, Anthropic CEO

As LLMs become more capable, three questions become critical:

1. **Why do these models say what they do?** â†’ Interpretability
2. **How do we make them do what we actually want?** â†’ Alignment  
3. **How do we know they're safe to deploy?** â†’ Safety Evaluation

This roadmap ensures you understand not just the **engineering** of LLMs, but the **science** of making them trustworthy.

---

## ğŸ›  Technical Stack Covered

<div align="left">

### Core Languages & Frameworks
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)
![CUDA](https://img.shields.io/badge/CUDA-76B900?style=for-the-badge&logo=nvidia&logoColor=white)
![C++](https://img.shields.io/badge/C++-00599C?style=for-the-badge&logo=cplusplus&logoColor=white)

### Deep Learning & LLMs
![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white)
![Hugging Face](https://img.shields.io/badge/Hugging%20Face-%F0%9F%A4%97-yellow?style=for-the-badge)
![Transformers](https://img.shields.io/badge/Transformers-FFD21E?style=for-the-badge)
![TransformerLens](https://img.shields.io/badge/TransformerLens-4B0082?style=for-the-badge)

### Alignment & Safety
![TRL](https://img.shields.io/badge/TRL-FF6B6B?style=for-the-badge)
![RLHF](https://img.shields.io/badge/RLHF-00CED1?style=for-the-badge)
![DPO](https://img.shields.io/badge/DPO-9370DB?style=for-the-badge)
![SAE](https://img.shields.io/badge/SAE-20B2AA?style=for-the-badge)

### Infrastructure & Deployment
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)
![Kubernetes](https://img.shields.io/badge/kubernetes-%23326ce5.svg?style=for-the-badge&logo=kubernetes&logoColor=white)
![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white)
![vLLM](https://img.shields.io/badge/vLLM-FF4500?style=for-the-badge)
<br/>
<code>FlashAttention</code> | <code>Triton</code> | <code>Ray</code> | <code>FSDP</code> | <code>DeepSpeed</code>

</div>

---

## ğŸ† Major Project Milestones

<div align="left" style="display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); gap: 20px; padding: 20px;">

  <div style="padding: 20px; border: 1px solid #30363d; border-radius: 10px; background: #0d1117; text-align: left;">
    <h3>ğŸ”§ NanoGPT from Scratch</h3>
    <p><strong>Week 2-4 | Transformer Fundamentals</strong></p>
    <p>Build a complete GPT-style transformer from the ground up. Implement attention mechanisms, training loops, and tokenization.</p>
    <p>
      <code>PyTorch</code> <code>Transformers</code> <code>Training</code>
    </p>
    <img src="https://img.shields.io/badge/Phase_1-Foundations-blue?style=for-the-badge" />
  </div>

  <div style="padding: 20px; border: 1px solid #30363d; border-radius: 10px; background: #0d1117; text-align: left;">
    <h3>âš¡ Model Quantization Pipeline</h3>
    <p><strong>Week 5-6 | Inference Optimization</strong></p>
    <p>Quantize models to INT4/INT8. Implement PTQ and QAT techniques. Deploy optimized inference with vLLM.</p>
    <p>
      <code>Quantization</code> <code>vLLM</code> <code>FlashAttention</code>
    </p>
    <img src="https://img.shields.io/badge/Phase_2-Optimization-purple?style=for-the-badge" />
  </div>

  <div style="padding: 20px; border: 1px solid #30363d; border-radius: 10px; background: #0d1117; text-align: left;">
    <h3>ğŸŒ Distributed Training System</h3>
    <p><strong>Week 10-11 | Multi-GPU Training</strong></p>
    <p>Implement DDP and FSDP training. Master tensor and pipeline parallelism. Build fault-tolerant training pipelines.</p>
    <p>
      <code>DDP</code> <code>FSDP</code> <code>ZeRO</code> <code>Ray</code>
    </p>
    <img src="https://img.shields.io/badge/Phase_3-Distributed-green?style=for-the-badge" />
  </div>

  <div style="padding: 20px; border: 1px solid #30363d; border-radius: 10px; background: #0d1117; text-align: left;">
    <h3>ğŸš€ Full-Stack LLM Application</h3>
    <p><strong>Week 17-18 | Production Capstone</strong></p>
    <p>End-to-end LLM application with RAG, MLOps pipeline, monitoring, and production deployment.</p>
    <p>
      <code>RAG</code> <code>MLOps</code> <code>CI/CD</code> <code>Monitoring</code>
    </p>
    <img src="https://img.shields.io/badge/Phase_4-Production-orange?style=for-the-badge" />
  </div>

  <div style="padding: 20px; border: 1px solid #30363d; border-radius: 10px; background: #0d1117; text-align: left;">
    <h3>ğŸ¯ RLHF Training Pipeline</h3>
    <p><strong>Week 19-20 | AI Alignment</strong></p>
    <p>Implement complete RLHF: SFT, reward modeling, and PPO. Compare with DPO and Constitutional AI approaches.</p>
    <p>
      <code>RLHF</code> <code>DPO</code> <code>TRL</code> <code>PPO</code>
    </p>
    <img src="https://img.shields.io/badge/Phase_5-Alignment-red?style=for-the-badge" />
  </div>

  <div style="padding: 20px; border: 1px solid #30363d; border-radius: 10px; background: #0d1117; text-align: left;">
    <h3>ğŸ”¬ Sparse Autoencoder Analysis</h3>
    <p><strong>Week 22-23 | Interpretability</strong></p>
    <p>Train SAEs on LLM activations. Discover and interpret features. Build visualization dashboards like Neuronpedia.</p>
    <p>
      <code>SAE</code> <code>TransformerLens</code> <code>Feature Analysis</code>
    </p>
    <img src="https://img.shields.io/badge/Phase_6-Interpretability-cyan?style=for-the-badge" />
  </div>

  <div style="padding: 20px; border: 1px solid #30363d; border-radius: 10px; background: #0d1117; text-align: left;">
    <h3>ğŸ›¡ï¸ Safety Evaluation Pipeline</h3>
    <p><strong>Week 25-27 | Final Capstone</strong></p>
    <p>Complete safety evaluation suite: capability evals, red teaming, interpretability analysis, and deployment recommendations.</p>
    <p>
      <code>Red Teaming</code> <code>Capability Evals</code> <code>Inspect</code>
    </p>
    <img src="https://img.shields.io/badge/Phase_7-Safety-yellow?style=for-the-badge" />
  </div>

</div>

---

## ğŸ“š Phase Deep Dives

### Phase 1-4: LLM Systems Foundations (Days 1-90)

<details>
<summary><strong>ğŸ”§ Phase 1: Foundations (Days 1-20)</strong></summary>

- GPU architecture and CUDA programming
- Transformer implementation from scratch
- Attention mechanisms deep dive
- Performance profiling and optimization
- Memory management strategies

</details>

<details>
<summary><strong>âš¡ Phase 2: Inference Optimization (Days 21-39)</strong></summary>

- Quantization (PTQ, QAT, GPTQ, AWQ)
- FlashAttention and memory-efficient attention
- KV-cache optimization
- Continuous batching
- LoRA and parameter-efficient fine-tuning

</details>

<details>
<summary><strong>ğŸŒ Phase 3: Distributed Systems (Days 40-59)</strong></summary>

- DDP and FSDP training
- ZeRO optimization stages
- Tensor and pipeline parallelism
- Fault-tolerant training
- RAG system architecture

</details>

<details>
<summary><strong>ğŸš€ Phase 4: Production (Days 60-90)</strong></summary>

- vLLM and Triton serving
- MLOps pipelines
- Monitoring and observability
- Edge deployment
- Full-stack capstone project

</details>

### Phase 5-7: AI Alignment & Safety (Days 91-135)

<details>
<summary><strong>ğŸ¯ Phase 5: AI Alignment (Days 91-105)</strong></summary>

- **RLHF Pipeline**: SFT â†’ Reward Modeling â†’ PPO
- **Direct Preference Optimization (DPO)**: Simpler alternative to RLHF
- **Constitutional AI**: Self-improvement through principles
- **Reward Hacking**: Goodhart's Law in practice
- **Alignment Faking**: Detecting strategic compliance

</details>

<details>
<summary><strong>ğŸ”¬ Phase 6: Mechanistic Interpretability (Days 106-120)</strong></summary>

- **Superposition**: Why neurons are polysemantic
- **Sparse Autoencoders**: Extracting interpretable features
- **Circuit Discovery**: Finding algorithms in networks
- **Activation Patching**: Causal analysis of components
- **Feature Steering**: Controlling model behavior

</details>

<details>
<summary><strong>ğŸ›¡ï¸ Phase 7: Advanced AI Safety (Days 121-135)</strong></summary>

- **Capability Evaluations**: CBRN, cyber, autonomy
- **Red Teaming**: Systematic failure discovery
- **Scalable Oversight**: Debate, recursive reward modeling
- **Weak-to-Strong Generalization**: Training from weak labels
- **Deception Detection**: Probing for honesty

</details>

---

## ğŸ“ˆ Learning Progress Tracker

```
Phase 1: Foundations          [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0%
Phase 2: Optimization         [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0%
Phase 3: Distributed          [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0%
Phase 4: Production           [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0%
Phase 5: Alignment            [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0%
Phase 6: Interpretability     [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0%
Phase 7: Safety               [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Overall Progress              [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0/135 Days
```

---

## ğŸ“ What You'll Master

By completing this roadmap, you will be able to:

### Systems Engineering
- [ ] Build a GPT-style transformer from scratch
- [ ] Quantize models to INT4/INT8 with minimal accuracy loss
- [ ] Fine-tune with LoRA and PEFT techniques
- [ ] Set up distributed training across multiple GPUs
- [ ] Deploy production inference servers with vLLM
- [ ] Build RAG systems with vector databases

### AI Alignment
- [ ] Implement complete RLHF pipeline (SFT â†’ RM â†’ PPO)
- [ ] Train models with DPO as an alternative to RLHF
- [ ] Explain Goodhart's Law and its implications
- [ ] Identify and diagnose reward hacking behaviors
- [ ] Understand Constitutional AI principles

### Interpretability
- [ ] Train and analyze Sparse Autoencoders (SAEs)
- [ ] Perform activation patching for causal analysis
- [ ] Identify circuits in transformer networks
- [ ] Apply feature steering to control behavior
- [ ] Use the logit lens for layer-by-layer analysis

### AI Safety
- [ ] Design comprehensive capability evaluations
- [ ] Conduct systematic red team testing
- [ ] Understand scalable oversight challenges
- [ ] Evaluate models for dangerous capabilities
- [ ] Build safety evaluation pipelines

---

## ğŸ“– Key Resources

### Essential Papers
| Category | Papers |
|:---------|:-------|
| **Alignment** | InstructGPT, DPO, Constitutional AI, Alignment Faking, Sleeper Agents |
| **Interpretability** | Toy Models of Superposition, Scaling Monosemanticity, Representation Engineering |
| **Safety** | Evaluating Frontier Models, Weak-to-Strong Generalization, Specification Gaming |

### Tools & Libraries
| Purpose | Tools |
|:--------|:------|
| **Training** | TRL, OpenRLHF, Axolotl, DeepSpeed |
| **Interpretability** | TransformerLens, SAE Lens, Neuronpedia |
| **Evaluation** | Inspect (UK AISI), lm-evaluation-harness |

### Recommended Reading
- ğŸ“• **RLHF Book** by Nathan Lambert
- ğŸ“— **AI Safety Fundamentals** by BlueDot Impact  
- ğŸ“˜ **ARENA Mechanistic Interpretability** course

---

## ğŸ—“ï¸ Study Schedule

| Day Type | Commitment | Activities |
|:---------|:-----------|:-----------|
| **Weekdays** | 2 hours/day | Daily lessons + exercises |
| **Weekends** | 4-6 hours | Weekly projects + review |
| **Total** | ~400 hours | Complete mastery journey |

---

## ğŸš€ Getting Started

```bash
# Clone the repository
git clone https://github.com/Darylwanji/135DaysofLLM.git

# Navigate to Day 1
cd 135DaysofLLM/Phase-1-Foundations

# Start your journey
open "Day 01 - GPU Architecture Deep Dive.md"
```

---

## ğŸ“« Let's Connect!

<div align="center">
  <a href="mailto:daryl.wanji@gmail.com">
    <img src="https://img.shields.io/badge/Gmail-333333?style=for-the-badge&logo=gmail&logoColor=red" />
  </a>
  <a href="https://www.linkedin.com/in/darylwanji" target="_blank">
    <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" />
  </a>
  <a href="https://github.com/Darylwanji" target="_blank">
    <img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white" />
  </a>
</div>

<p align="center">
  Open to collaboration, discussions, and study groups! Whether you're just starting your LLM journey or deep into alignment research, let's learn together.
</p>

---

<div align="center">
  <img src="https://readme-typing-svg.herokuapp.com/?font=Righteous&size=18&center=true&vCenter=true&width=500&height=50&duration=4000&lines=Build+LLMs+That+Are+Capable;Align+Them+With+Human+Values;Understand+What's+Inside;Deploy+Them+Safely" />
</div>

<p align="center">
  <em>Started: January 5, 2026 | Target Completion: July 18, 2026</em>
</p>

---

<div align="center">
  <sub>â­ Star this repo if you find it helpful!</sub>
</div>
